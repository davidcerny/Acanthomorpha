---
title: "SortaDate Analysis"
author: "David Cerny"
date: "3/16/2017"
output: html_document
---

# Individual UCEs

The gene trees were constructed using ETE toolkit:

Preparatory step: installing Miniconda, following the instructions from <http://etetoolkit.org/download/>

```{r, echo = FALSE, eval = FALSE}
curl -L 'http://repo.continuum.io/miniconda/Miniconda2-latest-MacOSX-x86_64.sh' -o Miniconda2-latest-MacOSX-x86_64.sh

# Note that the original link does not work

bash Miniconda2-latest-MacOSX-x86_64.sh -b -p ~/anaconda_ete/

# Output:
#
# PREFIX=/Users/David/anaconda_ete
# installing: python-2.7.13-0 ...
# installing: cffi-1.9.1-py27_0 ...
# installing: conda-env-2.6.0-0 ...
# installing: cryptography-1.7.1-py27_0 ...
# installing: enum34-1.1.6-py27_0 ...
# installing: idna-2.2-py27_0 ...
# installing: ipaddress-1.0.18-py27_0 ...
# installing: openssl-1.0.2k-0 ...
# installing: pyasn1-0.1.9-py27_0 ...
# installing: pycosat-0.6.1-py27_1 ...
# installing: pycparser-2.17-py27_0 ...
# installing: pyopenssl-16.2.0-py27_0 ...
# installing: readline-6.2-2 ...
# installing: requests-2.12.4-py27_0 ...
# installing: ruamel_yaml-0.11.14-py27_1 ...
# installing: setuptools-27.2.0-py27_0 ...
# installing: six-1.10.0-py27_0 ...
# installing: sqlite-3.13.0-0 ...
# installing: tk-8.5.18-0 ...
# installing: yaml-0.1.6-0 ...
# installing: zlib-1.2.8-3 ...
# installing: conda-4.3.11-py27_0 ...
# installing: pip-9.0.1-py27_1 ...
# installing: wheel-0.29.0-py27_0 ...
# Python 2.7.13 :: Continuum Analytics, Inc.
# creating default environment...
# installation finished.

export PATH=~/anaconda_ete/bin:$PATH
conda install -c etetoolkit ete3 ete3_external_apps
ete3 build check
```

The gene trees were estimated using RAxML:

```
ete3 build -w standard_raxml -n /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/FASTA/uce-3.fasta -o /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/FASTA/uce-3-tree
```

Automatically generate the corresponding command for each of the 230 alignment files in the directory:

```
cd /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/FASTA
ls
```

Copy the output to a text file:

```{r, eval=FALSE}
# Get the 1st part of the command

locus_table <- read.table("Set1-individual-loci.txt")
n <- length(unlist(locus_table))

inputfile <- vector()
for(i in locus_table) {
  inputfile <- append(inputfile, paste("ete3 build -w standard_raxml -n /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/FASTA/", i, sep = ""))
}

# Length check

length(inputfile) - n

# Remove file endings from the locus names

names_and_endings <- as.character(as.vector(as.matrix(locus_table)))
locus_names <- vector()
for(i in names_and_endings) {
  locus_names <- append(locus_names, sapply(strsplit(i, split='.', fixed=TRUE), function(x) (x[1])))
}

# Get the 2nd part of the command

outputfile <- vector()
for(i in locus_names) {
  outputfile <- append(outputfile, paste(" -o /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/", i, sep=""))
}

# Length check

length(outputfile) - n

# Get the entire command

commands <- paste(inputfile, outputfile, "-tree &&", sep="")

# Length check

length(commands) - n

# Uncomment to print to file:
# write(commands, "gene-tree-analysis.sh")
```

`#!/bin/bash` was then inserted into the first line of the file to convert it into a shell script. The script was run as follows:

```
chmod 755 /Users/David/Grive/Alfaro_Lab/SortaDate/Locus_analysis/gene-tree-analysis.sh
/Users/David/Grive/Alfaro_Lab/SortaDate/Locus_analysis/gene-tree-analysis.sh
```

Write a new script that will copy the trees from the nested subdirectories to the same directory where the alignment files are located:

```{r, eval = FALSE}
# 1st part of the command

copyfiles <- vector()
for(i in locus_names) {
  copyfiles <- append(copyfiles, paste("cp /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/", i, sep = ""))
}

# 2nd part of the command

subdirectories <- vector()
for(i in locus_names) {
  subdirectories <- append(subdirectories, paste("-tree/clustalo_default-none-none-raxml_default/", i, sep = ""))
}

# Get the entire command

copying <- paste(copyfiles, subdirectories, ".fasta.final_tree.nw /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/FASTA/ &&", sep="")

# Uncomment to print to file:
# write(copying, "copy-trees.sh")
```

Write a third script to rename the tree files so that they have the `.tre` file ending, which SortaDate looks for while searching its target directory:

```{r, eval = FALSE}
# 1st part of the command

oldname <- vector()
for(i in locus_names) {
  oldname <- append(oldname, paste("mv /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/FASTA/", i, sep = ""))
}

# 2nd part of the command

newname <- vector()
for(i in locus_names) {
  newname <- append(newname, paste(".fasta.final_tree.nw /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/FASTA/", i, sep = ""))
}

# Get the entire command:

renametrees <- paste(oldname, newname, ".tre &&", sep = "")

# Uncomment to print to file:
write(renametrees, "rename-trees.sh")
```

### Phase 1: get_var_length

```
python src/get_var_length.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/FASTA/ --flend .tre --outf Locus_analysis/var-uces --outg alepisaurus_ferox,ceratoscopelus_warmingii
```

```{r comment='', eval=FALSE, echo = FALSE}
cat(readLines("Locus_analysis/var-uces"), sep = '\n')
```

### Phase 2: get_bp_genetrees

```
python src/get_bp_genetrees.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/FASTA/ /Users/David/Grive/Alfaro_Lab/Acanthomorpha/12_no_outgroups_scheme_3.tre --flend .tre --outf Locus_analysis/bp-uces
```

```{r comment='', eval=FALSE, echo = FALSE}
cat(readLines("Locus_analysis/bp-uces"), sep = '\n')
```

### Phase 3: combine_results

```
python src/combine_results.py Locus_analysis/var-uces Locus_analysis/bp-uces --outf Locus_analysis/comb-uces
```

```{r comment='', eval=FALSE, echo = FALSE}
cat(readLines("Locus_analysis/comb-uces"), sep = '\n')
```

### Phase 4: get_good_genes

In order of descending priority: bipartition support, root-to-tip variance, tree length

```
python src/get_good_genes.py Locus_analysis/comb-uces --max 3 --order 3,1,2 --outf Locus_analysis/gg-uces-312
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Locus_analysis/gg-uces-312"), sep = '\n')
```

In order of descending priority: bipartition support, tree length, root-to-tip variance

```
python src/get_good_genes.py Locus_analysis/comb-uces --max 3 --order 3,2,1 --outf Locus_analysis/gg-uces-321
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Locus_analysis/gg-uces-321"), sep = '\n')
```

In order of descending priority: root-to-tip variance, tree length, bipartition support

```
python src/get_good_genes.py Locus_analysis/comb-uces --max 3 --order 1,2,3 --outf Locus_analysis/gg-uces-123
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Locus_analysis/gg-uces-123"), sep = '\n')
```

In order of descending priority: root-to-tip variance, bipartition support, tree length

```
python src/get_good_genes.py Locus_analysis/comb-uces --max 3 --order 1,3,2 --outf Locus_analysis/gg-uces-132
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Locus_analysis/gg-uces-132"), sep = '\n')
```

In order of descending priority: tree length, root-to-tip variance, bipartition support

```
python src/get_good_genes.py Locus_analysis/comb-uces --max 3 --order 2,1,3 --outf Locus_analysis/gg-uces-213
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Locus_analysis/gg-uces-213"), sep = '\n')
```

In order of descending priority: tree length, bipartition support, root-to-tip variance

```
python src/get_good_genes.py Locus_analysis/comb-uces --max 3 --order 2,3,1 --outf Locus_analysis/gg-uces-231
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Locus_analysis/gg-uces-231"), sep = '\n')
```

# k-means partitions

Note that the largest, slowest-evolving partition ("ccf55a6ee6d62f840a124bcc0c98ecf5"; 132 kb) was excluded from the first round of analyses for computational reasons. Attempts to analyze it in RAxML after the remaining 31 analyses finished up were unsuccessful.

```{r, eval=FALSE}
# Get the 1st part of the command

kmeans_table <- read.table("Set2-kmeans-partitions.txt")
n2 <- length(unlist(kmeans_table))

first <- vector()
for(i in kmeans_table) {
  first <- append(first, paste("ete3 build -w standard_raxml -n /Users/David/Grive/Alfaro_Lab/Acanthomorpha/k-means_partitions/", i, sep = ""))
}

# Length check

length(first) - n2

# Remove file endings from the locus names

no_endings <- as.character(as.vector(as.matrix(kmeans_table)))
kmeans_names <- vector()
for(i in no_endings) {
  kmeans_names <- append(kmeans_names, sapply(strsplit(i, split='.', fixed=TRUE), function(x) (x[1])))
}
kmeans_names

# Get the 2nd part of the command

second <- vector()
for(i in kmeans_names) {
  second <- append(second, paste(" -o /Users/David/Grive/Alfaro_Lab/Acanthomorpha/k-means_partitions/", i, sep=""))
}
second

# Length check

length(second) - n2

# Get the entire command

kmeansscript <- paste(first, second, "-tree &&", sep="")

# Length check

length(kmeansscript) - n2

# Uncomment to print to file:
# write(kmeansscript, "kmeans-analysis.sh")
```

Copy the trees into the directory containing the alignments:

```{r, eval = FALSE}
# 1st part of the command

copytrees <- vector()
for(i in kmeans_names) {
  copytrees <- append(copytrees, paste("cp /Users/David/Grive/Alfaro_Lab/Acanthomorpha/k-means_partitions/", i, sep = ""))
}

# 2nd part of the command

locations <- vector()
for(i in kmeans_names) {
  locations <- append(locations, paste("-tree/clustalo_default-none-none-raxml_default/", i, sep = ""))
}

# Get the entire command

finalstep <- paste(copytrees, locations, ".phy.fasta.final_tree.nw /Users/David/Grive/Alfaro_Lab/Acanthomorpha/k-means_partitions/FASTA/ &&", sep="")

# Uncomment to print to file:
# write(finalstep, "copy-kmeans-trees.sh")
```

Change the tree names so that they correspond to the partition names:

```{r, eval = FALSE}
# 1st part of the command

oldtreename <- vector()
for(i in kmeans_names) {
  oldtreename <- append(oldtreename, paste("mv /Users/David/Grive/Alfaro_Lab/Acanthomorpha/k-means_partitions/FASTA/", i, sep = ""))
}

# 2nd part of the command

newtreename <- vector()
for(i in kmeans_names) {
  newtreename <- append(newtreename, paste(".phy.fasta.final_tree.nw /Users/David/Grive/Alfaro_Lab/Acanthomorpha/k-means_partitions/FASTA/", i, sep = ""))
}

# Get the entire command:

changetreenames <- paste(oldtreename, newtreename, ".tre &&", sep = "")

# Uncomment to print to file:
# write(changetreenames, "rename-kmeans-trees.sh")
```

Finally, rename the partitions:

```{r, eval = FALSE}
# 1st part of the command

oldpartition <- vector()
for(i in kmeans_names) {
  oldpartition <- append(oldpartition, paste("mv /Users/David/Grive/Alfaro_Lab/Acanthomorpha/k-means_partitions/FASTA/", i, sep = ""))
}

# 2nd part of the command

newpartition <- vector()
for(i in kmeans_names) {
  newpartition <- append(newpartition, paste(".phy.fasta /Users/David/Grive/Alfaro_Lab/Acanthomorpha/k-means_partitions/FASTA/", i, sep = ""))
}

# Get the entire command
  
renamepartitions <- paste(oldpartition, newpartition, ".fasta &&", sep = "")

# Uncomment to print to file:
# write(renamepartitions, "rename-partitions.sh")
```

### Phase 1: get_var_length

```
python src/get_var_length.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/k-means_partitions/FASTA/ --flend .tre --outf var-kmeans --outg alepisaurus_ferox,ceratoscopelus_warmingii
```

```{r eval = FALSE, comment='', echo = FALSE, message=F, warning=F}
cat(readLines("kmeans_analysis/var-kmeans"), sep = '\n')
```

### Phase 2: get_bp_genetrees

```
python src/get_bp_genetrees.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/k-means_partitions/FASTA/ /Users/David/Grive/Alfaro_Lab/Acanthomorpha/12_no_outgroups_scheme_3.tre --flend .tre --outf bp-kmeans
```

```{r eval = FALSE, comment='', echo = FALSE, message=F, warning=F}
cat(readLines("kmeans_analysis/bp-kmeans"), sep = '\n')
```

### Phase 3: combine_results

```
python src/combine_results.py var-kmeans bp-kmeans --outf comb-kmeans
```

```{r eval = FALSE, comment='', echo = FALSE, message=F, warning=F}
cat(readLines("kmeans_analysis/comb-kmeans"), sep = '\n')
```

### Phase 4: get_good_genes

In order of descending priority: bipartition support, root-to-tip variance, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py kmeans_analysis/comb-kmeans --max 3 --order 3,1,2 --outf kmeans_analysis/gg-kmeans-312
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("kmeans_analysis/gg-kmeans-312"), sep = '\n')
```

In order of descending priority: bipartition support, tree length, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py kmeans_analysis/comb-kmeans --max 3 --order 3,2,1 --outf kmeans_analysis/gg-kmeans-321
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("kmeans_analysis/gg-kmeans-321"), sep = '\n')
```

In order of descending priority: root-to-tip variance, tree length, bipartition support 

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py kmeans_analysis/comb-kmeans --max 3 --order 1,2,3 --outf kmeans_analysis/gg-kmeans-123
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("kmeans_analysis/gg-kmeans-123"), sep = '\n')
```

In order of descending priority: root-to-tip variance, bipartition support, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py kmeans_analysis/comb-kmeans --max 3 --order 1,3,2 --outf kmeans_analysis/gg-kmeans-132
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("kmeans_analysis/gg-kmeans-132"), sep = '\n')
```

In order of descending priority: tree length, root-to-tip variance, bipartition support

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py kmeans_analysis/comb-kmeans --max 3 --order 2,1,3 --outf kmeans_analysis/gg-kmeans-213
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("kmeans_analysis/gg-kmeans-213"), sep = '\n')
```

In order of descending priority: tree length, bipartition support, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py kmeans_analysis/comb-kmeans --max 3 --order 2,3,1 --outf kmeans_analysis/gg-kmeans-231
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("kmeans_analysis/gg-kmeans-231"), sep = '\n')
```

# 50-bp Chunks

A bash script was written to automate the following actions:

1. Create a new directory nested in `/Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/FASTA` for each locus
2. Split the alignments for each locus into individual sequences, and these into 50-bp chunks. This step was performed using a custom Python script obtained from http://www.reddit.com/r/bioinformatics/comments/1u8yc7/looking_for_a_script_that_will_split_dna/ceg8rav/?st=j0tbjfco&sh=1e300055. 

    ```
      '''
      Splits all sequences within a multi-fasta file into chunks of a specified size.
      
      Fasta header information is retained with each split sequence - its position in
      the original is appended to the id. Single-line and multi-line fasta files are
      supported. Prints to stout, so pipe to a file to store the result.
      
      Usage:
      python splitter.py <filename> <chunksize>
      python splitter.py myfile.fa 100
      '''
      
      from __future__ import print_function
      from sys import argv, version
      
      if version[0] == '2':
          from itertools import izip_longest as zl
      else:
          from itertools import zip_longest as zl
          
      chunksize = int(argv[2])
      
      def writeseq(header, seq):
          for i, chunk in enumerate(zl(*[iter(seq)]*chunksize, fillvalue='')):
              print(header + '_{}bp'.format(i*chunksize))
              print(''.join(chunk))
              
      with open(argv[1]) as f:
          header, seq = f.readline().rstrip(), ''
          for l in f:
              if l[0] != '>':
                  seq += l.rstrip()
              else:
                  writeseq(header, seq)
                  header, seq = l.rstrip(), ''
          writeseq(header, seq)
    ```

3. For each locus, join the individual sequences chunk-wise (i.e., make a single fasta file for all taxa and sites 0 to 50, another one for all taxa and sites 51 to 100, etc.):

    ```{r, eval = FALSE}
    library(dplyr)

    # Alternating rows (name, sequence, name, sequence) go to two different columns, so that
    # each sequence is correctly assigned to its respective taxon:

    split_seqs <- read.table("split.txt")
    odd <- as.vector(split_seqs[seq(1, nrow(split_seqs), 2), ])
    even <- as.vector(split_seqs[seq(2, nrow(split_seqs), 2), ])
    odd_name <- "taxon"
    even_name <- "sequence"
    split_seqs_new <- data.frame(odd, even)
    names(split_seqs_new) <- c(odd_name, even_name)

    # Determine how long the locus is (i.e., how many 50-bp chunks it has been split into).
    # This can be done by counting the number of occurrences of a single taxon name. 
    # In principle, any name could be used, but since not all of the UCEs include
    # all of the taxa, it is advisable to choose a taxon common to all the loci.

    n <- length(unique(grep("chaetodon_kleinii", split_seqs_new[,1], value = TRUE)))

    # Create a vector of strings that can filter taxon names according to the base pair range
    # tag attached to their end

    chunks <- vector()
    for(i in 0:(n-1)) {
      chunks <- append(chunks, paste("_", i*50, "bp", sep = ""))
    }

    # Create a list of data frames. Each element of the list represents a base pair range
    # and consists of a data frame containing both the "taxon" and "sequence" columns of
    # split_seqs_new

    partition <- list()
    for(i in 1:length(chunks)) {
      partition[[i]] <- data.frame(filter(split_seqs_new, 
                                          grepl(as.character(chunks[i]), taxon)))
    }

    # Create a matrix whose columns represents individual chunks (i.e., base pair ranges)
    # and whose rows have the structure of the original split_seqs data frame -- i.e., name,
    # sequence, name, sequence:

    chunkmatrix <- matrix(ncol = length(partition), 
                          nrow = 2*(nrow(split_seqs_new)/length(partition)))
    for(i in 1:length(partition)) {
      for(j in 1:nrow(partition[[i]])) {
        chunkmatrix[(2*j - 1), i] <- as.character(partition[[i]][j, "taxon"])
        chunkmatrix[2*j, i] <- as.character(partition[[i]][j, "sequence"])
      }
    }

    # Print the resulting fasta files!

    for(i in 1:ncol(chunkmatrix)) {
      write(chunkmatrix[,i], paste("chunk_", i, ".fasta", sep = ""))
    }
    ```

4. Add a locus-indicating prefix to all the chunks of a given UCE:
    
    ```
    find *.fasta -maxdepth 0 ! -path . -exec mv {} uce-1005_{} \;
    ```
    
5. Copy the resulting fasta files into a single directory.

The contents of the directory were then summarized as follows:

```
cd /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks/
ls > /Users/David/Grive/Alfaro_Lab/SortaDate/Set3-50bp-chunks.txt
```

Now, change the taxon names in the chunk FASTA files so that they correspond to the names in the reference tree. First, create a file with the names of all the chunk files:

```
cd /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks/
ls *.fasta > /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks/chunklist.txt
```

```{r, eval=FALSE}
a <- read.table("/Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks/chunklist.txt")

x <- vector()
for(i in 1:nrow(a)) {
  x <- append(x, paste("/Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks/", a[i,], sep = ""))
}

for(i in 1:length(x)) {
  c <- read.table(print(x[i]), stringsAsFactors = FALSE)
  d <- vector()
  for(j in 1:(nrow(c)/2)) {
    d[j] <- as.character(c[(2*j-1),])
  }
  
  e <- vector()
  for(j in 1:length(d)) {
    e[j] <- paste(sapply(strsplit(d[j], split="_", fixed=TRUE), function(x) (x[1])), 
                  "_", 
                  sapply(strsplit(d[j], split="_", fixed=TRUE), function(x) (x[2])),
                  sep = "")
  }
  
  for(j in 1:(nrow(c)/2)) {
    c[(2*j-1),] <- e[j]
  }
  write(as.matrix(c), print(x[i]), ncolumns=1)
}
```

A script was generated to analyze all of the alignment in the directory using RAxML:

```{r, eval=FALSE}
chunk_table <- read.table("Set3-50bp-chunks.txt")

newfolders <- vector()
for(i in chunk_table) {
  newfolders <- append(newfolders, paste("ete3 build -w standard_raxml -n /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks/", i, sep=""))
}

with_endings <- as.character(as.vector(as.matrix(chunk_table)))
chunk_names <- vector()
for(i in with_endings) {
  chunk_names <- append(chunk_names, sapply(strsplit(i, split='.', fixed=TRUE), function(x) (x[1])))
}

tree_location <- vector()
for(i in chunk_names) {
  tree_location <- append(tree_location, paste(" -o /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/", i, sep=""))
}

analyzechunks <- paste(newfolders, tree_location, sep="")
write(analyzechunks, "chunk-analysis.sh")
```

The resulting tree files were then copied into the directory containing the alignments:

```{r, eval = FALSE}
copyfrom1 <- vector()
for(i in chunk_names) {
  copyfrom1 <- append(copyfrom1, paste("cp /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/", i, sep = ""))
}

copyfrom2 <- vector()
for(i in chunk_names) {
  copyfrom2 <- append(copyfrom2, paste("/clustalo_default-none-none-raxml_default/", i, sep = ""))
}

copyto <- paste(copyfrom1, copyfrom2, ".fasta.final_tree.nw /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks/", sep="")

write(copyto, "copy-chunk-trees.sh")
```

Rename the trees:

```
brew install rename
rename -S .fasta.final_tree.nw .tre *.fasta.final_tree.nw
```

Running `ls *.fasta | wc -l` and `ls *.nw | wc -l` in the directory showed that out of 1826 chunk FASTA files, no more than 1070 had tree files associated with them.

### Phase 1: get_var_length

```
python src/get_var_length.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks/ --flend .tre --outf Chunk_analysis/var-chunks --outg alepisaurus_ferox,ceratoscopelus_warmingii
```

### Phase 2: get_bp_genetrees

```
python src/get_bp_genetrees.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks/ /Users/David/Grive/Alfaro_Lab/Acanthomorpha/12_no_outgroups_scheme_3.tre --flend .tre --outf Chunk_analysis/bp-chunks
```

### Phase 3: combine_results

```
python src/combine_results.py Chunk_analysis/var-chunks Chunk_analysis/bp-chunks --outf Chunk_analysis/comb-chunks
```

Calculate the Robinson-Foulds distances of the individual chunk trees from the reference tree using the Python script below:

```
import os, uuid
from ete3 import Tree

t2 = Tree("/Users/David/Grive/Alfaro_Lab/Acanthomorpha/12_no_outgroups_scheme_3.tre")
for file in os.listdir("/Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks/"):
    if file.endswith(".tre"):
        t1 = Tree(file)
        try:
            rf = t1.robinson_foulds(t2)
            print str(file), (rf[0])
        except:
            pass
```

```{r, echo=FALSE}
l <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk_analysis/comb-chunks")
colnames(l) <- c("name", "root_to_tip_var", "treelength", "bipartition")
hist(l$bipartition, xlab = "Bipartition support", col="cornflowerblue", main="Histogram of bipartition support (all chunks)")
hist(l$root_to_tip_var, breaks = 5000, xlim=c(0,.47), xlab = "Root-to-tip variance", col="greenyellow", main="Histogram of root-to-tip variance\n(all chunks, excluding outliers)")
hist(l$treelength, xlab = "Tree length", breaks = 5000, xlim=c(0, .47), col="lightcoral", main="Histogram of tree length (all chunks)")
```

```{r, echo = FALSE}
a <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk_analysis/Robinson-Foulds_Chunks.txt")
hist(a[,2], xlab = "Robinson-Foulds distance", breaks=c(seq(min(a[,2]), max(a[,2]), by = 2)), 
     col="mediumpurple", main="RF distance distribution across chunks")
```

#### Step 1 of filtering: remove trees of zero length

No effect: the minimum observed tree length is non-zero and equal to:

```{r, echo = FALSE}
l <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk_analysis/comb-chunks")
colnames(l) <- c("name", "root_to_tip_var", "treelength", "bipartition")
min(l$treelength)
```

### Phase 4: get_good_genes

In order of descending priority: bipartition support, root-to-tip variance, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk_analysis/comb-chunks --max 3 --order 3,1,2 --outf Chunk_analysis/gg-chunks-312
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk_analysis/gg-chunks-312"), sep = '\n')
```

```{r, echo = FALSE}
chunks <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk_analysis/gg-chunks-312", stringsAsFactors = FALSE)
distances <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk_analysis/Robinson-Foulds_Chunks.txt", stringsAsFactors = FALSE)
colnames(distances) <- c("chunk", "rf")
best <- distances[distances$chunk == chunks[2,1],]
secondbest <- distances[distances$chunk == chunks[3,1],]
thirdbest <- distances[distances$chunk == chunks[4,1],]
print("The Robinson-Foulds distances of the three bets chunks from the reference tree are as follows:")
best
secondbest
thirdbest
```

The chunk with the minimum RF distance from the reference tree:

```{r, echo = FALSE}
minimum <- distances[distances$rf == min(distances$rf),]
print(minimum)
```

In order of descending priority: bipartition support, tree length, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk_analysis/comb-chunks --max 3 --order 3,2,1 --outf Chunk_analysis/gg-chunks-321
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk_analysis/gg-chunks-321"), sep = '\n')
```

In order of descending priority: root-to-tip variance, tree length, bipartition support 

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk_analysis/comb-chunks --max 3 --order 1,2,3 --outf Chunk_analysis/gg-chunks-123
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk_analysis/gg-chunks-123"), sep = '\n')
```

In order of descending priority: root-to-tip variance, bipartition support, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk_analysis/comb-chunks --max 3 --order 1,3,2 --outf Chunk_analysis/gg-chunks-132
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk_analysis/gg-chunks-132"), sep = '\n')
```

In order of descending priority: tree length, root-to-tip variance, bipartition support

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk_analysis/comb-chunks --max 3 --order 2,1,3 --outf Chunk_analysis/gg-chunks-213
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk_analysis/gg-chunks-213"), sep = '\n')
```

In order of descending priority: tree length, bipartition support, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk_analysis/comb-chunks --max 3 --order 2,3,1 --outf Chunk_analysis/gg-chunks-231
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk_analysis/gg-chunks-231"), sep = '\n')
```

## 50-bp chunks: SH-like of 75% or above

1. Copy all the tree files to a new directory:

    ```
    cd /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa
    mkdir Chunks_75
    cp Chunks/*.tre Chunks_75
    ```

2. Collapse all the nodes with SH-like support values of less than 75% using the following Python script:

    ```
    import os, uuid
    from ete3 import Tree

    for file in os.listdir("/Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks"):
        if file.endswith(".tre"):
            outname = "/Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks_75/" + str(file)
            t = Tree(file, format=0)

            print t.get_ascii(attributes=['support', 'name'])

            for node in t.get_descendants():
                if not node.is_leaf() and node.support <= 0.75:
                    node.delete()

            print t.get_ascii(attributes=['support', 'name'])

            t.write(format=0, outfile=outname)
    ```

3. Copy the fasta alignments to the same directory:

    ```
    cp Chunks/*.fasta Chunks_75
    ```
    
### Phase 1: get_var_length

```
python src/get_var_length.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks_75/ --flend .tre --outf Chunk75_analysis/var-chunks75 --outg alepisaurus_ferox,ceratoscopelus_warmingii
```

### Phase 2: get_bp_genetrees

```
python src/get_bp_genetrees.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks_75/ /Users/David/Grive/Alfaro_Lab/Acanthomorpha/12_no_outgroups_scheme_3.tre --flend .tre --outf Chunk75_analysis/bp-chunks75
```

### Phase 3: combine_results

```
python src/combine_results.py Chunk75_analysis/var-chunks75 Chunk75_analysis/bp-chunks75 --outf Chunk75_analysis/comb-chunks75
```

A script was written to delete all lines containing NAs, as well as all lines that only contained an entry for bipartition support but none for root-to-tip branch length variance or tree length. This was accomplished by filling these partially empty lines with NAs in the first step and deleting them in the second step:

```{r, eval = FALSE}
combchunks75 <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk75_analysis/comb-chunks75", fill = TRUE)
filtered <- na.omit(combchunks75)
write.table(filtered,
      "/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk75_analysis/comb-chunks75-filtered",
      sep = "\t",
      quote = FALSE,
      row.names = FALSE,
      col.names = FALSE)
```

The length of the filtered comb file is 901 lines, meaning that SortaDate failed to obtain root-to-tip variance and/or tree length for 169 trees.

```{r, echo=FALSE}
z <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk75_analysis/comb-chunks75-filtered")
colnames(z) <- c("name", "root_to_tip_var", "treelength", "bipartition")
hist(z$bipartition, xlab = "Bipartition support", breaks=30, col="cornflowerblue", main="Histogram of bipartition support (SH-like > 0.75)")
hist(z$root_to_tip_var, xlim=c(0, 1), breaks = 5000, xlab = "Root-to-tip variance", col="greenyellow", main="Histogram of root-to-tip variance\n(SH-like > 0.75, excluding outliers)")
hist(z$treelength, xlab = "Tree length", col="lightcoral", main="Histogram of tree length (SH-like > 0.75)")
```

```{r, echo = FALSE}
b <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk75_analysis/Robinson-Foulds_Chunks_75.txt")
hist(b[,2], xlab = "Robinson-Foulds distance", breaks=c(seq(min(b[,2]), max(b[,2]), by = 1)), 
     col="mediumpurple", main="RF distance distribution across chunks (SH-like > 0.75)")
```

#### Step 1 of filtering: remove trees of zero length

No effect: the minimum observed tree length is non-zero and equal to:

```{r, echo = FALSE}
z <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk75_analysis/comb-chunks75-filtered")
colnames(z) <- c("name", "root_to_tip_var", "treelength", "bipartition")
min(z$treelength)
```

Note that this result is orders of magnitude larger than those observed in the other five chunk datasets.

### Phase 4: get_good_genes

In order of descending priority: bipartition support, root-to-tip variance, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk75_analysis/comb-chunks75-filtered --max 3 --order 3,1,2 --outf Chunk75_analysis/gg-chunks75-312
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk75_analysis/gg-chunks75-312"), sep = '\n')
```

```{r, echo=FALSE}
chunks <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk75_analysis/gg-chunks75-312", stringsAsFactors = FALSE)
distances <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk75_analysis/Robinson-Foulds_Chunks_75.txt", stringsAsFactors = FALSE)
colnames(distances) <- c("chunk", "rf")
best <- distances[distances$chunk == chunks[2,1],]
secondbest <- distances[distances$chunk == chunks[3,1],]
thirdbest <- distances[distances$chunk == chunks[4,1],]
print("The Robinson-Foulds distances of the three best chunks from the reference tree are as follows:")
best
secondbest
thirdbest
```

The chunk with the minimum RF distance from the reference tree:

```{r, echo = FALSE}
minimum <- distances[distances$rf == min(distances$rf),]
print(minimum)
```

In order of descending priority: bipartition support, tree length, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk75_analysis/comb-chunks75-filtered --max 3 --order 3,2,1 --outf Chunk75_analysis/gg-chunks75-321
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk75_analysis/gg-chunks75-321"), sep = '\n')
```

In order of descending priority: root-to-tip variance, tree length, bipartition support 

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk75_analysis/comb-chunks75-filtered --max 3 --order 1,2,3 --outf Chunk75_analysis/gg-chunks75-123
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk75_analysis/gg-chunks75-123"), sep = '\n')
```

In order of descending priority: root-to-tip variance, bipartition support, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk75_analysis/comb-chunks75-filtered --max 3 --order 1,3,2 --outf Chunk75_analysis/gg-chunks75-132
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk75_analysis/gg-chunks75-132"), sep = '\n')
```

In order of descending priority: tree length, root-to-tip variance, bipartition support

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk75_analysis/comb-chunks75-filtered --max 3 --order 2,1,3 --outf Chunk75_analysis/gg-chunks75-213
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk75_analysis/gg-chunks75-213"), sep = '\n')
```

In order of descending priority: tree length, bipartition support, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk75_analysis/comb-chunks75-filtered --max 3 --order 2,3,1 --outf Chunk75_analysis/gg-chunks75-231
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk75_analysis/gg-chunks75-231"), sep = '\n')
```

## 50-bp chunks: SH-like of 90% or above

(The first three steps were identical to those described above.)
    
### Phase 1: get_var_length

```
python src/get_var_length.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks_90/ --flend .tre --outf Chunk90_analysis/var-chunks90 --outg alepisaurus_ferox,ceratoscopelus_warmingii
```

```{r comment='', eval=FALSE, echo = FALSE}
cat(readLines("Chunk90_analysis/var-chunks90"), sep = '\n')
```

### Phase 2: get_bp_genetrees

```
python src/get_bp_genetrees.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-114-taxa/Chunks_90/ /Users/David/Grive/Alfaro_Lab/Acanthomorpha/12_no_outgroups_scheme_3.tre --flend .tre --outf Chunk90_analysis/bp-chunks90
```

```{r comment='', eval=FALSE, echo = FALSE}
cat(readLines("Chunk90_analysis/bp-chunks90"), sep = '\n')
```

### Phase 3: combine_results

```
python src/combine_results.py Chunk90_analysis/var-chunks90 Chunk90_analysis/bp-chunks90 --outf Chunk90_analysis/comb-chunks90
```

```{r comment='', eval=FALSE, echo = FALSE}
cat(readLines("Chunk90_analysis/comb-chunks75"), sep = '\n')
```

Delete the lines with NAs:

```{r, eval = FALSE}
combchunks90 <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk90_analysis/comb-chunks90", fill = TRUE)
filtered <- na.omit(combchunks90)
write.table(filtered,
      "/Users/David/Grive/Alfaro_Lab/SortaDate/comb-chunks90-filtered",
      sep = "\t",
      quote = FALSE,
      row.names = FALSE,
      col.names = FALSE)
```

The length of the filtered comb file is 536 lines, meaning that SortaDate failed to obtain root-to-tip variance and/or tree length for 534 (almost 50%) trees.

```{r, echo=FALSE}
a <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk90_analysis/comb-chunks90-filtered")
colnames(a) <- c("name", "root_to_tip_var", "treelength", "bipartition")
hist(a$bipartition, xlab = "Bipartition support", col="cornflowerblue", main="Histogram of bipartition support (SH-like > 0.9)")
hist(a$root_to_tip_var, xlim=c(0, 5), breaks = 5000, xlab = "Root-to-tip variance", col="greenyellow", main="Histogram of root-to-tip variance\n(SH-like > 0.9, excluding outliers)")
hist(a$treelength, xlab = "Tree length", col="lightcoral", main="Histogram of tree length (SH-like > 0.9)")
```

```{r, echo = FALSE}
c <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk90_analysis/Robinson-Foulds_Chunks_90.txt")
hist(c[,2], xlab = "Robinson-Foulds distance", breaks=c(seq(min(c[,2]), max(c[,2]), by = 1)), 
     col="mediumpurple", main="RF distance distribution across chunks (SH-like > 0.9)")
```

#### Step 1 of filtering: remove trees of zero length

No effect: the minimum observed tree length is non-zero and equal to:

```{r, echo = FALSE}
a <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk90_analysis/comb-chunks90-filtered")
colnames(a) <- c("name", "root_to_tip_var", "treelength", "bipartition")
min(a$treelength)
```

### Phase 4: get_good_genes

In order of descending priority: bipartition support, root-to-tip variance, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk90_analysis/comb-chunks90-filtered --max 3 --order 3,1,2 --outf Chunk90_analysis/gg-chunks90-312
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk90_analysis/gg-chunks90-312"), sep = '\n')
```

```{r, echo=FALSE}
chunks <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk90_analysis/gg-chunks90-312", stringsAsFactors = FALSE)
distances <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Chunk90_analysis/Robinson-Foulds_Chunks_90.txt", stringsAsFactors = FALSE)
colnames(distances) <- c("chunk", "rf")
best <- distances[distances$chunk == chunks[2,1],]
secondbest <- distances[distances$chunk == chunks[3,1],]
thirdbest <- distances[distances$chunk == chunks[4,1],]
print("The Robinson-Foulds distances of the three best chunks from the reference tree are as follows:")
best
secondbest
thirdbest
```

The chunk with the minimum RF distance from the reference tree:

```{r, echo = FALSE}
minimum <- distances[distances$rf == min(distances$rf),]
print(minimum)
```

In order of descending priority: bipartition support, tree length, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk90_analysis/comb-chunks90-filtered --max 3 --order 3,2,1 --outf Chunk90_analysis/gg-chunks90-321
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk90_analysis/gg-chunks90-321"), sep = '\n')
```

In order of descending priority: root-to-tip variance, tree length, bipartition support 

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk90_analysis/comb-chunks90-filtered --max 3 --order 1,2,3 --outf Chunk90_analysis/gg-chunks90-123
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk90_analysis/gg-chunks90-123"), sep = '\n')
```

In order of descending priority: root-to-tip variance, bipartition support, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk90_analysis/comb-chunks90-filtered --max 3 --order 1,3,2 --outf Chunk90_analysis/gg-chunks90-132
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk90_analysis/gg-chunks90-132"), sep = '\n')
```

In order of descending priority: tree length, root-to-tip variance, bipartition support

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk90_analysis/comb-chunks90-filtered --max 3 --order 2,1,3 --outf Chunk90_analysis/gg-chunks90-213
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk90_analysis/gg-chunks90-213"), sep = '\n')
```

In order of descending priority: tree length, bipartition support, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Chunk90_analysis/comb-chunks90-filtered --max 3 --order 2,3,1 --outf Chunk90_analysis/gg-chunks90-231
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Chunk90_analysis/gg-chunks90-231"), sep = '\n')
```

# 50-bp chunks from the 75%-complete dataset

A bash script used to split the UCE loci into 50-bp chunks was identical to that used above, with the exception of step 3 (joining all taxa represented by a given chunk into a new FASTA file), for which the following code was used:

```{r, eval = FALSE}
library(dplyr)

# Alternating rows (name, sequence, name, sequence) go to two different columns, so that
# each sequence is correctly assigned to its respective taxon:

split_seqs <- read.table("split.txt")
odd <- as.vector(split_seqs[seq(1, nrow(split_seqs), 2), ])
even <- as.vector(split_seqs[seq(2, nrow(split_seqs), 2), ])
odd_name <- "taxon"
even_name <- "sequence"
split_seqs_new <- data.frame(odd, even)
names(split_seqs_new) <- c(odd_name, even_name)

# Determine how long the locus is (i.e., how many 50-bp chunks it has been split into).
# This can be done by counting the number of occurrences of a single taxon name. 
# In principle, any name could be used, but since no taxon appears to be common to all
# the loci, the code below grabs the first taxon name appearing in the fasta file and
# counts its occurrences.

m <- paste(sapply(strsplit(as.character(split_seqs_new[1,1]), split="_", fixed=TRUE),
                  function(x) (x[1])), 
           "_", sapply(strsplit(as.character(split_seqs_new[1,1]), split="_", fixed=TRUE),                         function(x) (x[2])),
           sep = "")
n <- length(unique(grep(m, split_seqs_new[,1], value = TRUE)))

# Create a vector of strings that can filter taxon names according to the base pair range
# tag attached to their end

chunks <- vector()
for(i in 0:(n-1)) {
  chunks <- append(chunks, paste("_", i*50, "bp", sep = ""))
}

# Create a list of data frames. Each element of the list represents a base pair range
# and consists of a data frame containing both the "taxon" and "sequence" columns of
# split_seqs_new

partition <- list()
for(i in 1:length(chunks)) {
partition[[i]] <- data.frame(filter(split_seqs_new, 
                                    grepl(as.character(chunks[i]), taxon)))
}

# Create a matrix whose columns represents individual chunks (i.e., base pair ranges)
# and whose rows have the structure of the original split_seqs data frame -- i.e., name,
# sequence, name, sequence:

chunkmatrix <- matrix(ncol = length(partition), 
                      nrow = 2*(nrow(split_seqs_new)/length(partition)))
for(i in 1:length(partition)) {
  for(j in 1:nrow(partition[[i]])) {
    chunkmatrix[(2*j - 1), i] <- as.character(partition[[i]][j, "taxon"])
    chunkmatrix[2*j, i] <- as.character(partition[[i]][j, "sequence"])
  }
}

# Print the resulting fasta files!

for(i in 1:ncol(chunkmatrix)) {
  write(chunkmatrix[,i], paste("chunk_", i, ".fasta", sep = ""))
}
```

The taxon names in the chunk FASTA files were then stripped of the chunk-indicating suffixes so as to correspond with the names used in the reference tree, and a script was used to analyze all the chunks using RAxML. The resulting trees were then copied into the directory containing the chunks. Out of 6543 chunk FASTA files, only 4237 had tree files associated with them, suggesting that RAxML failed to infer a tree for a given chunk in approx. 35% of cases.

### Phase 1: get_var_length

```
python src/get_var_length.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-90-taxa/Chunks/ --flend .tre --outf Min-90-chunk_analysis/var-min-90-chunks --outg alepisaurus_ferox,ceratoscopelus_warmingii
```

Running the script produced 1029 warnings about either *Alepisaurus ferox* or *Ceratoscopelus warmingii* missing from the chunk tree. Despite this, the tree length and root-to-tip variance was computed for all the 4237 trees.

### Phase 2: get_bp_genetrees

```
python src/get_bp_genetrees.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-90-taxa/Chunks/ /Users/David/Grive/Alfaro_Lab/Acanthomorpha/12_no_outgroups_scheme_3.tre --flend .tre --outf Min-90-chunk_analysis/bp-min-90-chunks
```

### Phase 3: combine_results

```
python src/combine_results.py Min-90-chunk_analysis/var-min-90-chunks Min-90-chunk_analysis/bp-min-90-chunks --outf Min-90-chunk_analysis/comb-min-90-chunks
```

```{r, echo=FALSE}
k <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk_analysis/comb-min-90-chunks")
colnames(k) <- c("name", "root_to_tip_var", "treelength", "bipartition")
hist(k$bipartition, xlab = "Bipartition support", col="cornflowerblue", main="Histogram of bipartition support (75%-complete dataset)")
hist(k$root_to_tip_var, breaks = 5000, xlim=c(0,1), xlab = "Root-to-tip variance", col="greenyellow", main="Histogram of root-to-tip variance\n(75%-complete dataset, excluding outliers)")
hist(k$treelength, xlab = "Tree length", col="lightcoral", main="Histogram of tree length (75%-complete dataset)")
```

```{r, echo = FALSE}
d <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk_analysis/Robinson-Foulds_min-90-chunks.txt")
hist(d[,2], xlab = "Robinson-Foulds distance", breaks=c(seq(min(d[,2]), max(d[,2]), by = 2)), col="mediumpurple", main="RF distance distribution across chunks (75%-complete dataset)")
```

### Phase 4: get_good_genes

In order of descending priority: bipartition support, root-to-tip variance, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk_analysis/comb-min-90-chunks --max 3 --order 3,1,2 --outf Min-90-chunk_analysis/gg-min-90-chunks-312
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk_analysis/gg-min-90-chunks-312"), sep = '\n')
```

```{r, echo=FALSE}
chunks <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk_analysis/gg-min-90-chunks-312", stringsAsFactors = FALSE)
distances <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk_analysis/Robinson-Foulds_min-90-chunks.txt", stringsAsFactors = FALSE)
colnames(distances) <- c("chunk", "rf")
best <- distances[distances$chunk == chunks[2,1],]
secondbest <- distances[distances$chunk == chunks[3,1],]
thirdbest <- distances[distances$chunk == chunks[4,1],]
print("The Robinson-Foulds distances of the three best chunks from the reference tree are as follows:")
best
secondbest
thirdbest
```

The chunk with the minimum RF distance from the reference tree:

```{r, echo = FALSE}
minimum <- distances[distances$rf == min(distances$rf),]
print(minimum)
```

In order of descending priority: bipartition support, tree length, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk_analysis/comb-min-90-chunks --max 3 --order 3,2,1 --outf Min-90-chunk_analysis/gg-min-90-chunks-321
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk_analysis/gg-min-90-chunks-321"), sep = '\n')
```

In order of descending priority: root-to-tip variance, tree length, bipartition support 

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk_analysis/comb-min-90-chunks --max 3 --order 1,2,3 --outf Min-90-chunk_analysis/gg-min-90-chunks-123
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk_analysis/gg-min-90-chunks-123"), sep = '\n')
```

In order of descending priority: root-to-tip variance, bipartition support, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk_analysis/comb-min-90-chunks --max 3 --order 1,3,2 --outf Min-90-chunk_analysis/gg-min-90-chunks-132
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk_analysis/gg-min-90-chunks-132"), sep = '\n')
```

In order of descending priority: tree length, root-to-tip variance, bipartition support

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk_analysis/comb-min-90-chunks --max 3 --order 2,1,3 --outf Min-90-chunk_analysis/gg-min-90-chunks-213
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk_analysis/gg-min-90-chunks-213"), sep = '\n')
```

In order of descending priority: tree length, bipartition support, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk_analysis/comb-min-90-chunks --max 3 --order 2,3,1 --outf Min-90-chunk_analysis/gg-min-90-chunks-231
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk_analysis/gg-min-90-chunks-231"), sep = '\n')
```

#### Step 1 of filtering: remove trees of zero length

No effect: the minimum observed tree length is non-zero and equal to:

```{r, echo = FALSE}
k <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk_analysis/comb-min-90-chunks")
colnames(k) <- c("name", "root_to_tip_var", "treelength", "bipartition")
min(k$treelength)
cat("Number of trees after filtering:", nrow(k))
cat("Percentage of trees after filtering: ", (100*nrow(k)/nrow(k)), "%", sep = "")
```

```{r, echo = FALSE}
plot(k$bipartition, k$treelength, xlab = "Bipartition support", ylab = "Tree length", main = "75%-complete dataset: tree length vs. bipartition support")
abline(lm(k$treelength ~ k$bipartition))
plot(k$bipartition, k$root_to_tip_var, xlab = "Bipartition support", ylab = "Root-to-tip variance", main = "75%-complete dataset: clockiness vs. bipartition support")
abline(lm(k$root_to_tip_var ~ k$bipartition))
plot(k$root_to_tip_var, k$treelength, xlab = "Root-to-tip variance", ylab = "Tree length", main = "75%-complete dataset: tree length vs. clockiness")
abline(lm(k$treelength ~ k$root_to_tip_var))
```

#### Step 2 of filtering: remove the shortest and longest 10% of trees:

```{r, echo = FALSE}
k <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk_analysis/comb-min-90-chunks")
colnames(k) <- c("name", "root_to_tip_var", "treelength", "bipartition")
min75filt2 <- k[k$treelength < quantile(k$treelength, 0.9) & k$treelength > quantile(k$treelength, 0.1),]
cat("Original min. tree length:", min(k$treelength))
cat("Original max. tree length:", max(k$treelength))
cat("Min. tree length after step 2:", min(min75filt2$treelength))
cat("Max. tree length after step 2:", max(min75filt2$treelength))
cat("Number of trees after step 2:", nrow(min75filt2))
cat("Percentage of trees after step 2: ", (100*nrow(min75filt2)/nrow(k)), "%", sep = "")
```

```{r, echo = FALSE}
plot(min75filt2$bipartition, min75filt2$treelength, xlab = "Bipartition support", ylab = "Tree length", main = "75%-complete dataset: tree length vs. bipartition support\nafter step 2 of filtering")
abline(lm(min75filt2$treelength ~ min75filt2$bipartition))
plot(min75filt2$bipartition, min75filt2$root_to_tip_var, xlab = "Bipartition support", ylab = "Root-to-tip variance", main = "75%-complete dataset: clockiness vs. bipartition support\nafter step 2 of filtering")
abline(lm(min75filt2$root_to_tip_var ~ min75filt2$bipartition))
plot(min75filt2$root_to_tip_var, min75filt2$treelength, xlab = "Root-to-tip variance", ylab = "Tree length", main = "75%-complete dataset: tree length vs. clockiness\nafter step 2 of filtering")
abline(lm(min75filt2$treelength ~ min75filt2$root_to_tip_var))
```

#### Step 3 of filtering: remove the most unclocklike third of loci

```{r, echo = FALSE}
k <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk_analysis/comb-min-90-chunks")
colnames(k) <- c("name", "root_to_tip_var", "treelength", "bipartition")
min75filt2 <- k[k$treelength < quantile(k$treelength, 0.9) & k$treelength > quantile(k$treelength, 0.1),]
min75filt3 <- min75filt2[min75filt2$root_to_tip_var < quantile(min75filt2$root_to_tip_var, 0.67),]
cat("Max. root-to-tip variance from step 2:", max(min75filt2$root_to_tip_var))
cat("Max. root-to-tip variance after step 3:", max(min75filt3$root_to_tip_var))
cat("Number of trees after step 3:", nrow(min75filt3))
cat("Percentage of trees after step 3: ", (100*nrow(min75filt3)/nrow(k)), "%", sep = "")
```

```{r, echo = FALSE}
plot(min75filt3$bipartition, min75filt3$treelength, xlab = "Bipartition support", ylab = "Tree length", main = "75%-complete dataset: tree length vs. bipartition support\nafter step 3 of filtering")
abline(lm(min75filt3$treelength ~ min75filt3$bipartition))
plot(min75filt3$bipartition, min75filt3$root_to_tip_var, xlab = "Bipartition support", ylab = "Root-to-tip variance", main = "75%-complete dataset: clockiness vs. bipartition support\nafter step 3 of filtering")
abline(lm(min75filt3$root_to_tip_var ~ min75filt3$bipartition))
plot(min75filt3$root_to_tip_var, min75filt3$treelength, xlab = "Root-to-tip variance", ylab = "Tree length", main = "75%-complete dataset: tree length vs. clockiness\nafter step 3 of filtering")
abline(lm(min75filt3$treelength ~ min75filt3$root_to_tip_var))
```

#### Step 4 of filtering: keep the loci in the upper 10% of bipartition support

```{r, echo = FALSE}
k <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk_analysis/comb-min-90-chunks")
colnames(k) <- c("name", "root_to_tip_var", "treelength", "bipartition")
min75filt2 <- k[k$treelength < quantile(k$treelength, 0.9) & k$treelength > quantile(k$treelength, 0.1),]
min75filt3 <- min75filt2[min75filt2$root_to_tip_var < quantile(min75filt2$root_to_tip_var, 0.67),]
min75filt4 <- min75filt3[min75filt3$bipartition > quantile(min75filt3$bipartition, 0.9),]
cat("Min. bipartition support from step 3:", min(min75filt3$bipartition))
cat("Min. bipartition support after step 4:", min(min75filt4$bipartition))
cat("Number of trees after step 4:", nrow(min75filt4))
cat("Percentage of trees after step 4: ", (100*nrow(min75filt4)/nrow(k)), "%", sep = "")
```

```{r, echo = FALSE}
plot(min75filt4$bipartition, min75filt4$treelength, xlab = "Bipartition support", ylab = "Tree length", main = "75%-complete dataset: tree length vs. bipartition support\nafter step 4 of filtering")
abline(lm(min75filt4$treelength ~ min75filt4$bipartition))
plot(min75filt4$bipartition, min75filt4$root_to_tip_var, xlab = "Bipartition support", ylab = "Root-to-tip variance", main = "75%-complete dataset: clockiness vs. bipartition support\nafter step 4 of filtering")
abline(lm(min75filt4$root_to_tip_var ~ min75filt4$bipartition))
plot(min75filt4$root_to_tip_var, min75filt4$treelength, xlab = "Root-to-tip variance", ylab = "Tree length", main = "75%-complete dataset: tree length vs. clockiness\nafter step 4 of filtering")
abline(lm(min75filt4$treelength ~ min75filt4$root_to_tip_var))
```

## 50-bp chunks from the 75%-complete dataset: SH-like of 75% or above

The nodes with SH-like support values below 75% were collapsed using the script above. The corresponding FASTA files were copied into the resulting directory, and SortaDate was run as follows:

### Phase 1: get_var_length

```
python src/get_var_length.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-90-taxa/Chunks_75/ --flend .tre --outf Min-90-chunk75_analysis/var-min-90-chunks75 --outg alepisaurus_ferox,ceratoscopelus_warmingii
```

Running the script resulted in occasional segmentation faults as well as "this really only works with nexus or newick" warning messages. The resulting file had the full number of lines (4237: one for each tree), but some of them were blank and others contained NAs.

### Phase 2: get_bp_genetrees

```
python src/get_bp_genetrees.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-90-taxa/Chunks_75/ /Users/David/Grive/Alfaro_Lab/Acanthomorpha/12_no_outgroups_scheme_3.tre --flend .tre --outf Min-90-chunk75_analysis/bp-min-90-chunks75
```

### Phase 3: combine_results

```
python src/combine_results.py Min-90-chunk75_analysis/var-min-90-chunks75 Min-90-chunk75_analysis/bp-min-90-chunks75 --outf Min-90-chunk75_analysis/comb-min-90-chunks75
```

Delete the lines with NAs:

```{r, eval = FALSE}
comb90chunks75 <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk75_analysis/comb-min-90-chunks75", fill = TRUE)
filtered <- na.omit(comb90chunks75)
write.table(filtered,
      "/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk75_analysis/comb-min-90-chunks75-filtered",
      sep = "\t",
      quote = FALSE,
      row.names = FALSE,
      col.names = FALSE)
nrow(filtered)
```

The length of the filtered comb file is 3589 lines, meaning that SortaDate failed to obtain root-to-tip variance and/or tree length for 648 trees.

```{r, echo=FALSE}
g <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk75_analysis/comb-min-90-chunks75-filtered")
colnames(g) <- c("name", "root_to_tip_var", "treelength", "bipartition")
hist(g$bipartition, xlab = "Bipartition support", col="cornflowerblue", main="Histogram of bipartition support\n(SH-like > 0.75, 75%-complete dataset)")
hist(g$root_to_tip_var, breaks = 5000, xlim = c(0,0.5), xlab = "Root-to-tip variance", col="greenyellow", main="Histogram of root-to-tip variance\n(SH-like > 0.75, 75%-complete dataset, excluding outliers)")
hist(g$treelength, xlab = "Tree length", col="lightcoral", main="Histogram of tree length (SH-like > 0.75, 75%-complete dataset)")
```

```{r, echo = FALSE}
d <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk75_analysis/Robinson-Foulds_min-90-chunks_75.txt")
hist(d[,2], xlab = "Robinson-Foulds distance", breaks=c(seq(min(d[,2]), max(d[,2]), by = 2)), col="mediumpurple", main="RF distance distribution across chunks\n(SH-like > 0.75, 75%-complete dataset)")
```

### Phase 4: get_good_genes

In order of descending priority: bipartition support, root-to-tip variance, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk75_analysis/comb-min-90-chunks75-filtered --max 3 --order 3,1,2 --outf Min-90-chunk75_analysis/gg-min-90-chunks75-312
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk75_analysis/gg-min-90-chunks75-312"), sep = '\n')
```

```{r, echo=FALSE}
chunks <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk75_analysis/gg-min-90-chunks75-312", stringsAsFactors = FALSE)
distances <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk75_analysis/Robinson-Foulds_min-90-chunks_75.txt", stringsAsFactors = FALSE)
colnames(distances) <- c("chunk", "rf")
best <- distances[distances$chunk == chunks[2,1],]
secondbest <- distances[distances$chunk == chunks[3,1],]
thirdbest <- distances[distances$chunk == chunks[4,1],]
print("The Robinson-Foulds distances of the three best chunks from the reference tree are as follows:")
best
secondbest
thirdbest
```

The chunk with the minimum RF distance from the reference tree:

```{r, echo = FALSE}
minimum <- distances[distances$rf == min(distances$rf),]
print(minimum)
```

In order of descending priority: bipartition support, tree length, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk75_analysis/comb-min-90-chunks75-filtered --max 3 --order 3,2,1 --outf Min-90-chunk75_analysis/gg-min-90-chunks75-321
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk75_analysis/gg-min-90-chunks75-321"), sep = '\n')
```

In order of descending priority: root-to-tip variance, tree length, bipartition support 

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk75_analysis/comb-min-90-chunks75-filtered --max 3 --order 1,2,3 --outf Min-90-chunk75_analysis/gg-min-90-chunks75-123
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk75_analysis/gg-min-90-chunks75-123"), sep = '\n')
```

In order of descending priority: root-to-tip variance, bipartition support, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk75_analysis/comb-min-90-chunks75-filtered --max 3 --order 1,3,2 --outf Min-90-chunk75_analysis/gg-min-90-chunks75-132
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk75_analysis/gg-min-90-chunks75-132"), sep = '\n')
```

In order of descending priority: tree length, root-to-tip variance, bipartition support

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk75_analysis/comb-min-90-chunks75-filtered --max 3 --order 2,1,3 --outf Min-90-chunk75_analysis/gg-min-90-chunks75-213
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk75_analysis/gg-min-90-chunks75-213"), sep = '\n')
```

In order of descending priority: tree length, bipartition support, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk75_analysis/comb-min-90-chunks75-filtered --max 3 --order 2,3,1 --outf Min-90-chunk75_analysis/gg-min-90-chunks75-231
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk75_analysis/gg-min-90-chunks75-231"), sep = '\n')
```

#### Step 1 of filtering: remove trees of zero length

No effect: the minimum observed tree length is non-zero and equal to:

```{r, echo = FALSE}
g <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk75_analysis/comb-min-90-chunks75-filtered")
colnames(g) <- c("name", "root_to_tip_var", "treelength", "bipartition")
min(g$treelength)
cat("Number of trees after filtering:", nrow(g))
cat("Percentage of trees after filtering: ", (100*nrow(g)/nrow(g)), "%", sep = "")
```

```{r, echo = FALSE}
plot(g$bipartition, g$treelength, xlab = "Bipartition support", ylab = "Tree length", main = "SH-like > 0.75, 75%-complete dataset:\ntree length vs. bipartition support")
abline(lm(g$treelength ~ g$bipartition))
plot(g$bipartition, g$root_to_tip_var, xlab = "Bipartition support", ylab = "Root-to-tip variance", main = "SH-like > 0.75, 75%-complete dataset:\nclockiness vs. bipartition support")
abline(lm(g$root_to_tip_var ~ g$bipartition))
plot(g$root_to_tip_var, g$treelength, xlab = "Root-to-tip variance", ylab = "Tree length", main = "SH-like > 0.75, 75%-complete dataset:\ntree length vs. clockiness")
abline(lm(g$treelength ~ g$root_to_tip_var))
```

#### Step 2 of filtering: remove the shortest and longest 10% of trees:

```{r, echo = FALSE}
g <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk75_analysis/comb-min-90-chunks75-filtered")
colnames(g) <- c("name", "root_to_tip_var", "treelength", "bipartition")
SH75filt2 <- g[g$treelength < quantile(g$treelength, 0.9) & g$treelength > quantile(g$treelength, 0.1),]
cat("Original min. tree length:", min(g$treelength))
cat("Original max. tree length:", max(g$treelength))
cat("Min. tree length after step 2:", min(SH75filt2$treelength))
cat("Max. tree length after step 2:", max(SH75filt2$treelength))
cat("Number of trees after step 2:", nrow(SH75filt2))
cat("Percentage of trees after step 2: ", (100*nrow(SH75filt2)/nrow(g)), "%", sep = "")
```

```{r, echo = FALSE}
plot(SH75filt2$bipartition, SH75filt2$treelength, xlab = "Bipartition support", ylab = "Tree length", main = "SH-like > 0.75, 75%-complete dataset:\ntree length vs. bipartition support step 2 of filtering")
abline(lm(SH75filt2$treelength ~ SH75filt2$bipartition))
plot(SH75filt2$bipartition, SH75filt2$root_to_tip_var, xlab = "Bipartition support", ylab = "Root-to-tip variance", main = "SH-like > 0.75, 75%-complete dataset:\nclockiness vs. bipartition support after step 2 of filtering")
abline(lm(SH75filt2$root_to_tip_var ~ SH75filt2$bipartition))
plot(SH75filt2$root_to_tip_var, SH75filt2$treelength, xlab = "Root-to-tip variance", ylab = "Tree length", main = "SH-like > 0.75, 75%-complete dataset:\ntree length vs. clockiness after step 2 of filtering")
abline(lm(SH75filt2$treelength ~ SH75filt2$root_to_tip_var))
```

#### Step 3 of filtering: remove the most unclocklike third of loci

```{r, echo = FALSE}
g <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk75_analysis/comb-min-90-chunks75-filtered")
colnames(g) <- c("name", "root_to_tip_var", "treelength", "bipartition")
SH75filt2 <- g[g$treelength < quantile(g$treelength, 0.9) & g$treelength > quantile(g$treelength, 0.1),]
SH75filt3 <- SH75filt2[SH75filt2$root_to_tip_var < quantile(SH75filt2$root_to_tip_var, 0.67),]
cat("Max. root-to-tip variance from step 2:", max(SH75filt2$root_to_tip_var))
cat("Max. root-to-tip variance after step 3:", max(SH75filt3$root_to_tip_var))
cat("Number of trees after step 3:", nrow(SH75filt3))
cat("Percentage of trees after step 3: ", (100*nrow(SH75filt3)/nrow(g)), "%", sep = "")
```

```{r, echo = FALSE}
plot(SH75filt3$bipartition, SH75filt3$treelength, xlab = "Bipartition support", ylab = "Tree length", main = "SH-like > 0.75, 75%-complete dataset:\ntree length vs. bipartition support step 3 of filtering")
abline(lm(SH75filt3$treelength ~ SH75filt3$bipartition))
plot(SH75filt3$bipartition, SH75filt3$root_to_tip_var, xlab = "Bipartition support", ylab = "Root-to-tip variance", main = "SH-like > 0.75, 75%-complete dataset:\nclockiness vs. bipartition support after step 3 of filtering")
abline(lm(SH75filt3$root_to_tip_var ~ SH75filt3$bipartition))
plot(SH75filt3$root_to_tip_var, SH75filt3$treelength, xlab = "Root-to-tip variance", ylab = "Tree length", main = "SH-like > 0.75, 75%-complete dataset:\ntree length vs. clockiness after step 3 of filtering")
abline(lm(SH75filt3$treelength ~ SH75filt3$root_to_tip_var))
```

#### Step 4 of filtering: keep the loci in the upper 10% of bipartition support

```{r, echo = FALSE}
g <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk75_analysis/comb-min-90-chunks75-filtered")
colnames(g) <- c("name", "root_to_tip_var", "treelength", "bipartition")
SH75filt2 <- g[g$treelength < quantile(g$treelength, 0.9) & g$treelength > quantile(g$treelength, 0.1),]
SH75filt3 <- SH75filt2[SH75filt2$root_to_tip_var < quantile(SH75filt2$root_to_tip_var, 0.67),]
SH75filt4 <- SH75filt3[SH75filt3$bipartition > quantile(SH75filt3$bipartition, 0.9),]
cat("Min. bipartition support from step 3:", min(SH75filt3$bipartition))
cat("Min. bipartition support after step 4:", min(SH75filt4$bipartition))
cat("Number of trees after step 4:", nrow(SH75filt4))
cat("Percentage of trees after step 4: ", (100*nrow(SH75filt4)/nrow(g)), "%", sep = "")
```

```{r, echo = FALSE}
plot(SH75filt4$bipartition, SH75filt4$treelength, xlab = "Bipartition support", ylab = "Tree length", main = "SH-like > 0.75, 75%-complete dataset:\ntree length vs. bipartition support step 4 of filtering")
abline(lm(SH75filt4$treelength ~ SH75filt4$bipartition))
plot(SH75filt4$bipartition, SH75filt4$root_to_tip_var, xlab = "Bipartition support", ylab = "Root-to-tip variance", main = "SH-like > 0.75, 75%-complete dataset:\nclockiness vs. bipartition support after step 4 of filtering")
abline(lm(SH75filt4$root_to_tip_var ~ SH75filt4$bipartition))
plot(SH75filt4$root_to_tip_var, SH75filt4$treelength, xlab = "Root-to-tip variance", ylab = "Tree length", main = "SH-like > 0.75, 75%-complete dataset:\ntree length vs. clockiness after step 4 of filtering")
abline(lm(SH75filt4$treelength ~ SH75filt4$root_to_tip_var))
```

## 50-bp chunks from the 75%-complete dataset: SH-like of 90% or above

### Phase 1: get_var_length

```
python src/get_var_length.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-90-taxa/Chunks_90/ --flend .tre --outf Min-90-chunk90_analysis/var-min-90-chunks90 --outg alepisaurus_ferox,ceratoscopelus_warmingii
```

As in the previous case, the command led to a number of segfaults and "this really only works with nexus or newick" warnings, corresponding to lines in the resulting file that were either incomplete or included NAs.

### Phase 2: get_bp_genetrees

```
python src/get_bp_genetrees.py /Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-90-taxa/Chunks_90/ /Users/David/Grive/Alfaro_Lab/Acanthomorpha/12_no_outgroups_scheme_3.tre --flend .tre --outf Min-90-chunk90_analysis/bp-min-90-chunks90
```

### Phase 3: combine_results

```
python src/combine_results.py Min-90-chunk90_analysis/var-min-90-chunks90 Min-90-chunk90_analysis/bp-min-90-chunks90 --outf Min-90-chunk90_analysis/comb-min-90-chunks90
```

Delete the lines with NAs:

```{r, eval = FALSE}
comb90chunks90 <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk90_analysis/comb-min-90-chunks90", fill = TRUE)
filtered <- na.omit(comb90chunks90)
write.table(filtered,
      "/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk90_analysis/comb-min-90-chunks90-filtered",
      sep = "\t",
      quote = FALSE,
      row.names = FALSE,
      col.names = FALSE)
nrow(filtered)
```

The length of the filtered comb file is 2319 lines, meaning that SortaDate failed to obtain root-to-tip variance and/or tree length for 1918 trees.

```{r, echo=FALSE}
h <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk90_analysis/comb-min-90-chunks90-filtered")
colnames(h) <- c("name", "root_to_tip_var", "treelength", "bipartition")
hist(h$bipartition, xlab = "Bipartition support", col="cornflowerblue", main="Histogram of bipartition support\n(SH-like > 0.9, 75%-complete dataset)")
hist(h$root_to_tip_var, breaks = 5000, xlim = c(0,2), xlab = "Root-to-tip variance", col="greenyellow", main="Histogram of root-to-tip variance\n(SH-like > 0.9, 75%-complete dataset, excluding outliers)")
hist(h$treelength, xlab = "Tree length", col="lightcoral", main="Histogram of tree length (SH-like > 0.9, 75%-complete dataset)")
```

```{r, echo = FALSE}
d <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk90_analysis/Robinson-Foulds_min-90-chunks_90.txt")
hist(d[,2], xlab = "Robinson-Foulds distance", breaks=c(seq(min(d[,2]), max(d[,2]), by = 2)), col="mediumpurple", main="RF distance distribution across chunks\n(SH-like > 0.9, 75%-complete dataset)")
```

### Phase 4: get_good_genes

In order of descending priority: bipartition support, root-to-tip variance, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk90_analysis/comb-min-90-chunks90-filtered --max 3 --order 3,1,2 --outf Min-90-chunk90_analysis/gg-min-90-chunks90-312
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk90_analysis/gg-min-90-chunks90-312"), sep = '\n')
```

```{r, echo=FALSE}
chunks <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk90_analysis/gg-min-90-chunks90-312", stringsAsFactors = FALSE)
distances <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk90_analysis/Robinson-Foulds_min-90-chunks_90.txt", stringsAsFactors = FALSE)
colnames(distances) <- c("chunk", "rf")
best <- distances[distances$chunk == chunks[2,1],]
secondbest <- distances[distances$chunk == chunks[3,1],]
thirdbest <- distances[distances$chunk == chunks[4,1],]
print("The Robinson-Foulds distances of the three best chunks from the reference tree are as follows:")
best
secondbest
thirdbest
```

The chunk with the minimum RF distance from the reference tree:

```{r, echo = FALSE}
minimum <- distances[distances$rf == min(distances$rf),]
print(minimum)
```

In order of descending priority: bipartition support, tree length, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk90_analysis/comb-min-90-chunks90-filtered --max 3 --order 3,2,1 --outf Min-90-chunk90_analysis/gg-min-90-chunks90-321
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk90_analysis/gg-min-90-chunks90-321"), sep = '\n')
```

In order of descending priority: root-to-tip variance, tree length, bipartition support 

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk90_analysis/comb-min-90-chunks90-filtered --max 3 --order 1,2,3 --outf Min-90-chunk90_analysis/gg-min-90-chunks90-123
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk90_analysis/gg-min-90-chunks90-123"), sep = '\n')
```

In order of descending priority: root-to-tip variance, bipartition support, tree length

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk90_analysis/comb-min-90-chunks90-filtered --max 3 --order 1,3,2 --outf Min-90-chunk90_analysis/gg-min-90-chunks90-132
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk90_analysis/gg-min-90-chunks90-132"), sep = '\n')
```

In order of descending priority: tree length, root-to-tip variance, bipartition support

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk90_analysis/comb-min-90-chunks90-filtered --max 3 --order 2,1,3 --outf Min-90-chunk90_analysis/gg-min-90-chunks90-213
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk90_analysis/gg-min-90-chunks90-213"), sep = '\n')
```

In order of descending priority: tree length, bipartition support, root-to-tip variance

```{r, echo = FALSE, eval = FALSE}
python src/get_good_genes.py Min-90-chunk90_analysis/comb-min-90-chunks90-filtered --max 3 --order 2,3,1 --outf Min-90-chunk90_analysis/gg-min-90-chunks90-231
```

```{r comment='', echo = FALSE, message=F, warning=F}
cat(readLines("Min-90-chunk90_analysis/gg-min-90-chunks90-231"), sep = '\n')
```

#### Step 1 of filtering: remove trees of zero length

No effect: the minimum observed tree length is non-zero and equal to:

```{r, echo = FALSE}
h <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk90_analysis/comb-min-90-chunks90-filtered")
colnames(h) <- c("name", "root_to_tip_var", "treelength", "bipartition")
min(h$treelength)
cat("Number of trees after filtering:", nrow(h))
cat("Percentage of trees after filtering: ", (100*nrow(h)/nrow(h)), "%", sep = "")
```

```{r, echo = FALSE}
plot(h$bipartition, h$treelength, xlab = "Bipartition support", ylab = "Tree length", main = "SH-like > 0.9, 75%-complete dataset:\ntree length vs. bipartition support")
abline(lm(h$treelength ~ h$bipartition))
plot(h$bipartition, h$root_to_tip_var, xlab = "Bipartition support", ylab = "Root-to-tip variance", main = "SH-like > 0.9, 75%-complete dataset:\nclockiness vs. bipartition support")
abline(lm(h$root_to_tip_var ~ h$bipartition))
plot(h$root_to_tip_var, h$treelength, xlab = "Root-to-tip variance", ylab = "Tree length", main = "SH-like > 0.9, 75%-complete dataset:\ntree length vs. clockiness")
abline(lm(h$treelength ~ h$root_to_tip_var))
```

#### Step 2 of filtering: remove the shortest and longest 10% of trees:

```{r, echo = FALSE}
h <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk90_analysis/comb-min-90-chunks90-filtered")
colnames(h) <- c("name", "root_to_tip_var", "treelength", "bipartition")
SH90filt2 <- h[h$treelength < quantile(h$treelength, 0.9) & h$treelength > quantile(h$treelength, 0.1),]
cat("Original min. tree length:", min(h$treelength))
cat("Original max. tree length:", max(h$treelength))
cat("Min. tree length after step 2:", min(SH90filt2$treelength))
cat("Max. tree length after step 2:", max(SH90filt2$treelength))
cat("Number of trees after step 2:", nrow(SH90filt2))
cat("Percentage of trees after step 2: ", (100*nrow(SH90filt2)/nrow(h)), "%", sep = "")
```

```{r, echo = FALSE}
plot(SH90filt2$bipartition, SH90filt2$treelength, xlab = "Bipartition support", ylab = "Tree length", main = "SH-like > 0.9, 75%-complete dataset:\ntree length vs. bipartition support step 2 of filtering")
abline(lm(SH90filt2$treelength ~ SH90filt2$bipartition))
plot(SH90filt2$bipartition, SH90filt2$root_to_tip_var, xlab = "Bipartition support", ylab = "Root-to-tip variance", main = "SH-like > 0.9, 75%-complete dataset:\nclockiness vs. bipartition support after step 2 of filtering")
abline(lm(SH90filt2$root_to_tip_var ~ SH90filt2$bipartition))
plot(SH90filt2$root_to_tip_var, SH90filt2$treelength, xlab = "Root-to-tip variance", ylab = "Tree length", main = "SH-like > 0.9, 75%-complete dataset:\ntree length vs. clockiness after step 2 of filtering")
abline(lm(SH90filt2$treelength ~ SH90filt2$root_to_tip_var))
```

#### Step 3 of filtering: remove the most unclocklike third of loci

```{r, echo = FALSE}
h <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk90_analysis/comb-min-90-chunks90-filtered")
colnames(h) <- c("name", "root_to_tip_var", "treelength", "bipartition")
SH90filt2 <- h[h$treelength < quantile(h$treelength, 0.9) & h$treelength > quantile(h$treelength, 0.1),]
SH90filt3 <- SH90filt2[SH90filt2$root_to_tip_var < quantile(SH90filt2$root_to_tip_var, 0.67),]
cat("Max. root-to-tip variance from step 2:", max(SH90filt2$root_to_tip_var))
cat("Max. root-to-tip variance after step 3:", max(SH90filt3$root_to_tip_var))
cat("Number of trees after step 3:", nrow(SH90filt3))
cat("Percentage of trees after step 3: ", (100*nrow(SH90filt3)/nrow(h)), "%", sep = "")
```

```{r, echo = FALSE}
plot(SH90filt3$bipartition, SH90filt3$treelength, xlab = "Bipartition support", ylab = "Tree length", main = "SH-like > 0.9, 75%-complete dataset:\ntree length vs. bipartition support step 3 of filtering")
abline(lm(SH90filt3$treelength ~ SH90filt3$bipartition))
plot(SH90filt3$bipartition, SH90filt3$root_to_tip_var, xlab = "Bipartition support", ylab = "Root-to-tip variance", main = "SH-like > 0.9, 75%-complete dataset:\nclockiness vs. bipartition support after step 3 of filtering")
abline(lm(SH90filt3$root_to_tip_var ~ SH90filt3$bipartition))
plot(SH90filt3$root_to_tip_var, SH90filt3$treelength, xlab = "Root-to-tip variance", ylab = "Tree length", main = "SH-like > 0.9, 75%-complete dataset:\ntree length vs. clockiness after step 3 of filtering")
abline(lm(SH90filt3$treelength ~ SH90filt3$root_to_tip_var))
```

#### Step 4 of filtering: keep the loci in the upper 10% of bipartition support

```{r, echo = FALSE}
h <- read.table("/Users/David/Grive/Alfaro_Lab/SortaDate/Min-90-chunk90_analysis/comb-min-90-chunks90-filtered")
colnames(h) <- c("name", "root_to_tip_var", "treelength", "bipartition")
SH90filt2 <- h[h$treelength < quantile(h$treelength, 0.9) & h$treelength > quantile(h$treelength, 0.1),]
SH90filt3 <- SH90filt2[SH90filt2$root_to_tip_var < quantile(SH90filt2$root_to_tip_var, 0.67),]
SH90filt4 <- SH90filt3[SH90filt3$bipartition > quantile(SH90filt3$bipartition, 0.9),]
cat("Min. bipartition support from step 3:", min(SH90filt3$bipartition))
cat("Min. bipartition support after step 4:", min(SH90filt4$bipartition))
cat("Number of trees after step 4:", nrow(SH90filt4))
cat("Percentage of trees after step 4: ", (100*nrow(SH90filt4)/nrow(h)), "%", sep = "")
```

```{r, echo = FALSE}
plot(SH90filt4$bipartition, SH90filt4$treelength, xlab = "Bipartition support", ylab = "Tree length", main = "SH-like > 0.9, 75%-complete dataset:\ntree length vs. bipartition support step 4 of filtering")
abline(lm(SH90filt4$treelength ~ SH90filt4$bipartition))
plot(SH90filt4$bipartition, SH90filt4$root_to_tip_var, xlab = "Bipartition support", ylab = "Root-to-tip variance", main = "SH-like > 0.9, 75%-complete dataset:\nclockiness vs. bipartition support after step 4 of filtering")
abline(lm(SH90filt4$root_to_tip_var ~ SH90filt4$bipartition))
plot(SH90filt4$root_to_tip_var, SH90filt4$treelength, xlab = "Root-to-tip variance", ylab = "Tree length", main = "SH-like > 0.9, 75%-complete dataset:\ntree length vs. clockiness after step 4 of filtering")
```

Out of the 66 chunks selected from the SH-like > 0.9 dataset, 65 were 50-bp long. To facilitate PartitionFinder searches, these chunks were aligned first using SequenceMatrix v1.8, with the last (47-bp) chunk attached to the resulting alignment afterwards. This made it easier to automate the calculation of base pair ranges for each locus (the latter needed to be included in the PartitionFinder configuration file). The outgroups (*Alepisaurus ferox* and *Ceratoscopelus warmingii*) were excluded from the concatenated alignment, as they were not present in the available topology constraint.

PartitionFinder was first run with the "rcluster" search option. Although the "models" option was set to "all", since rcluster searches can only be performed in RAxML, this effectively limited the analysis to the three models implemented in the latter software (GTR, GTR+$\Gamma$, GTR+$\Gamma$+I). This run yielded 8 subsets of the following properties:

Subset | Best Model | Sites | Rate under GTR+$\Gamma$ | ID                     
-------|------------|-------|-------------------------|---------------------------------
1      | GTR+$\Gamma$      | 1047  | 1.048826                | 76dec7513c9b37738bfac30d5d512cf3 
2      | GTR+I+$\Gamma$    | 1100  | 0.672610                | 111ec939b8c23b0e4e2529cee50f387a
3      | GTR+$\Gamma$      | 550   | 0.281570                | 00fea7ffef92b99d78df6650b56ebb0c
4      | GTR+$\Gamma$      | 100   | 0.965800                | 065a20f09eb1fa7383dedb55df51e100 
5      | GTR+$\Gamma$      | 200   | 2.278670                | a6afbf36fc27e68c089e09c31ca3c71f 
6      | GTR+$\Gamma$      | 50    | 1.682760                | da54ec6f6966e6b696433ef124df9e1f 
7      | GTR+I+$\Gamma$    | 50    | 2.739838                | 2d0d981211d9b6e3f364c1fcd221b555 
8      | GTR+$\Gamma$      | 200   | 1.356237                | fd9894d33a357dcdab10c55c5153eb16 

```{r, echo = FALSE}
sites <- c(1047, 1100, 550, 100, 200, 50, 50, 200)
scalers <- c(1.048826, 0.672610, 0.281570, 0.965800, 2.278670, 1.682760, 2.739838, 1.356237)
sitesnrates <- data.frame(sites, scalers)
plot(sitesnrates$sites, sitesnrates$scalers, xlab = "Number of sites in partition", ylab = "Branch length scaler", main = "Concatenated chunk partitions: sites vs. rates")
```

In the next step, the alignment was analyzed under the "greedy" search option, with the BEAST model set and without the "--raxml" flag. This search recovered the following 14 partitions:

Subset | Best Model | Sites | Tree size under the best model | ID
-------|------------|-------|--------------------------------|---
1      | HKY+$\Gamma$+X    | 100   | 6.07552                        | 3f353939a600a6973a6a1e0608925da6 
2      | TRNEF+$\Gamma$    | 200   | 4.34326                        | ceefdb63d1de1122404ab11285f05f27 
3      | JC+$\Gamma$       | 50    | 2.80253                        | ac2a21040350ec54b4664bc752a13a45 
4      | TRNEF+$\Gamma$    | 300   | 1.53147                        | baed377a41689244a752bc9e3169c975 
5      | GTR+I+$\Gamma$+X  | 350   | 3.44224                        | ce05da9c4ae84b4a74cb468b18fcda82 
6      | K80+I+$\Gamma$    | 450   | 3.71596                        | 16b9f71868c90950d0dd144fd5de511f 
7      | SYM+$\Gamma$      | 300   | 8.15389                        | c5076d62640bd9eeabe53de6e5bf7f7a 
8      | K80+$\Gamma$      | 150   | 9.20524                        | d5aeca1d1fad19fc89dbb336bad98cbd 
9      | K80+$\Gamma$      | 497   | 5.13898                        | e7f992b256534832ccdb46c09aa6e9a4 
10     | HKY+$\Gamma$+X    | 300   | 2.87180                        | 4e722846245f8cd6600c32f3131120a6 
11     | TRNEF+$\Gamma$    | 250   | 5.87708                        | 72ad9849e1f3be2cbffa1097935e00fc 
12     | GTR+I+$\Gamma$+X  | 50    | 36.99851                       | 2d0d981211d9b6e3f364c1fcd221b555 
13     | JC+$\Gamma$       | 150   | 1.20339                        | d687ea29d8ab88ed27334eafc8164ec8 
14     | TRNEF+$\Gamma$    | 150   | 13.44953                       | 00f862e3cabdf1be1b99bc5b1455ba78

(In PhyML, "tree size" denotes the sum of edge lengths: see http://github.com/stephaneguindon/phyml/blob/master/doc/phyml-manual.tex. "X" denotes estimated, as opposed to empirical, base frequencies.)

```{r, echo = FALSE}
sites2 <- c(100, 200, 50, 300, 350, 450, 300, 150, 497, 300, 250, 50, 150, 150)
scalers2 <- c(6.07552, 4.34326, 2.80253, 1.53147, 3.44224, 3.71596, 8.15389, 9.20524, 5.13898, 2.87180, 5.87708, 36.99851, 1.20339, 13.44953)
sitesnrates2 <- data.frame(sites2, scalers2)
plot(sitesnrates2$sites2, sitesnrates2$scalers2, xlab = "Number of sites in partition", ylab = "Sum of branch lengths", main = "Concatenated chunk partitions: sites vs. tree length")
```

#### BEAST analysis

The two 50-bp partitions were removed. Each partition received its own substitution model, which was generally identical to that selected by PartitionFinder, except for those models that contained the I parameter (proportion of invariant sites). Since this parameter and $\Gamma$ account for the same phenomenon (rate heterogeneity across sites), their simultaneous inclusion causes the resulting model to be non-identifiable, leading to potential mixing problems in MCMC simulations. The models that were not directly available in BEAUTi were implemented as follows:

- TrNef: TN93 + equal base frequencies
- K80: HKY85 + equal base frequencies
- SYM: GTR + equal base frequencies

Each $\Gamma$ rate heterogeneity distribution was discretized into 4 categories. The default improper prior on the relative rates (the `allMus` parameter) was set to a gamma distribution with a shape of 0.001 and a scale of 1000 following the recommendations at https://www.biostat.washington.edu/sites/default/files/modules//2016_SISMID_13_11.pdf. All the priors on substitution model parameters were kept at their default values. 

In contrast to the substitution models, the parameters of the uncorrelated lognormal clock model were linked across partitions. The `ucld.mean` hyperparameter was assigned a lognormal hyperprior with a mean of 0.005 (in real space) and a log standard deviation of 1, with the initial value set equal to 0.005. A truncated exponential hyperprior with support (0, 1), a mean of 0.3, and an initial value of 0.1 was used for `ucld.stdev`.

The "fixed tree topology" operator mix was used (based on a user-supplied topology common to all partitions), with the tuning of the `ucld.mean` and `ucld.stdev` operators set to 0.9 (default value = 0.75) and their weight doubled (from 3.0 to 6.0). Default tuning values and weights were used for all the remaining operators.

The 12 internal calibrations were all implemented as exponentials, and the (*Polymixia* + *Aphredoderus*) received the corrected calibration whose 95th percentile was equal to 116.35 Ma. A truncated exponential distribution supported on (98 Ma, 143 Ma) was constructed to calibrate the root of the tree, with its mean equal to the midpoint of the support interval (22.5 without the offset).

Finally, the MCMC simulation was run for 500 million generations, with a sampling period of 1000 generations.

```
beast -threads 12 -beagle_SSE concatchunks.xml
```

#### MCMCTree analysis

In PAML, subsets of a concatenated alignment cannot be simply ignored as in BEAST but must be removed from the file, so that the sum of partition lengths equals the total number of nucleotides (PAML manual: p. 13). Moreover, the sites that make up a partition must be adjacent in the alignment. Therefore, the following information from the `best_scheme` file generated by PartitionFinder was used to generate a PAML-compatible alignment:

```
1 locus42, locus1
2 locus57, locus3, locus25, locus2
3 locus4
4 locus61, locus5, locus55, locus63, locus23, locus47
5 locus16, locus54, locus45, locus31, locus7, locus64, locus6
6 locus15, locus24, locus8, locus11, locus53, locus52, locus51, locus20, locus26
7 locus14, locus17, locus9, locus27, locus22, locus28
8 locus10, locus21, locus13
9 locus62, locus37, locus59, locus29, locus12, locus58, locus46, locus66, locus44, locus18
10 locus40, locus39, locus49, locus19, locus32, locus38
11 locus35, locus60, locus33, locus43, locus30
12 locus34
13 locus36, locus48, locus65
14 locus56, locus50, locus41
```

1. Using bash, replace whitespaces between each taxon name and the corresponding sequence with line breaks:

    ```
    xargs -n 1 < concat.phy > concat2.phy
    ```

2. Manually remove the first line indicating the number of taxa and sites. 

3. Now, use the structure of the new file (with names and sequences in alternating rows) to reorganize the chunks:

    ```{r, eval = FALSE}
    concat <- read.table("/Users/David/Downloads/concat2.phy", stringsAsFactors = FALSE)

    # Random check, part 1: print "locus 42" (sites 2051--2100) of the first taxon:
    substring(concat[2,], 2051, 2100)

    for(i in seq(2, nrow(concat), by = 2)) {
      chunks <- substring(concat[i,], seq(1, 3250, 50), seq(50, 3250, 50))
      chunks[66] <- substring(concat[i,], 3251, 3297)
      ch1 <- paste(chunks[42], chunks[1], sep = "")
      ch2 <- paste(chunks[57], chunks[3], chunks[25], chunks[2], sep = "")
      ch3 <- paste(chunks[61], chunks[5], chunks[55], chunks[63], chunks[23], chunks[47], sep = "")
      ch4 <- paste(chunks[16], chunks[54], chunks[45], chunks[31], chunks[7], chunks[64], chunks[6], sep = "")
      ch5 <- paste(chunks[15], chunks[24], chunks[8], chunks[11], chunks[53], chunks[52], chunks[51], chunks[20], chunks[26], sep = "")
      ch6 <- paste(chunks[14], chunks[17], chunks[9], chunks[27], chunks[22], chunks[28], sep = "")
      ch7 <- paste(chunks[10], chunks[21], chunks[13], sep = "")
      ch8 <- paste(chunks[62], chunks[37], chunks[59], chunks[29], chunks[12], chunks[58], chunks[46], chunks[66], chunks[44], chunks[18], sep = "")
      ch9 <- paste(chunks[40], chunks[39], chunks[49], chunks[19], chunks[32], chunks[38], sep = "")
      ch10 <- paste(chunks[35], chunks[60], chunks[33], chunks[43], chunks[30], sep = "")
      ch11 <- paste(chunks[36], chunks[48], chunks[65], sep = "")
      ch12 <- paste(chunks[56], chunks[50], chunks[41], sep = "")
      concat[i,] <- paste(ch1, ch2, ch3, ch4, ch5, ch6, ch7, ch8, ch9, ch10, ch11, ch12, sep = "")
    }

    # Make sure that the new sequence rows have the desired length:
    for(i in seq(2, nrow(concat), by = 2)) {
      print(nchar(concat[i,]))
    }

    # Random check, part 2: "locus 42" should now correspond to sites 1--50. Does it?
    substring(concat[2,], 1, 50)

    # Yes! Now print the new alignment into a table:
    write.table(concat,
      "/Users/David/Grive/Alfaro_Lab/Acanthomorpha/sate-gblocks-clean-min-90-taxa/Concat/pamlconcat.phy",
      quote = FALSE,
      row.names = FALSE,
      col.names = FALSE)
    ```

4. Add the following two lines to the beginning of the file:

    ```
    118 3197 G
    G 12 100 200 300 350 450 300 150 497 300 250 150 150
    ```

Unlike BEAST, PAML cannot assign a separate substitution model to each partition, but it is capable of unlinking substitution model parameters across partitions (Warnock et al. 2014: ESM p. 2). Since moderate substitution model overparameterization usually does not pose a problem to Bayesian phylogenetic analyses (Ronquist & Deans 2010), each partition was assigned its own GTR+$\Gamma$ ("REV") model. Note that the unlinking of substitution models necessitates the use of empirical (`nhomo = 0`) rather than estimated base frequencies. Relative rate, equilibrium frequency, and alpha parameters were unlinked across partitions, but branch lengths were kept linked (options `Mgene = 4` and `Malpha = 1`). To facilitate cross-platform comparisons, the root calibration was set to 120.5 Ma (same as the mean of the root prior used in BEAST) in baseml to calculate substitution rates.

The substitution rate estimation finished up in 5:46:48 and yielded the following values:

Partition | Rate (subst. per 100 million years)
----------|------------------------------------
Gene 1    | 0.126608
Gene 2    | 0.087695
Gene 3    | 0.033200
Gene 4    | 0.072678
Gene 5    | 0.072362
Gene 6    | 0.158487
Gene 7    | 0.188372
Gene 8    | 0.107932
Gene 9    | 0.060550
Gene 10   | 0.111402
Gene 11   | 0.026772
Gene 12   | 0.184536

For MCMCTree, the G option cannot be used, and the partitions must be given as multiple alignments one after another in a single file (http://groups.google.com/forum/#!topic/pamlsoftware/cC7mOgZnNiY). Such a file was compiled as follows:

1. Run the following code:

    ```{r, eval = FALSE}
    concat <- read.table("/Users/David/Downloads/concat2.phy", stringsAsFactors = FALSE)
    
    alignments <- matrix(nrow = 12*(nrow(concat) + 2), ncol = 1)
    for(i in 1:(nrow(concat)/2)) {
    	for(j in 0:11) {
    		alignments[(2*i-1) + j*(nrow(concat) + 2), ] <- concat[(2*i-1),]
    	}
      chunks <- substring(concat[2*i,], seq(1, 3250, 50), seq(50, 3250, 50))
      chunks[66] <- substring(concat[2*i,], 3251, 3297)
      alignments[2*i,] <- paste(chunks[42], chunks[1], sep = "")
      alignments[2*i + 1*(nrow(concat) + 2),] <- paste(chunks[57], chunks[3], chunks[25], chunks[2], sep = "")
      alignments[2*i + 2*(nrow(concat) + 2),] <- paste(chunks[61], chunks[5], chunks[55], chunks[63], chunks[23], chunks[47], sep = "")
      alignments[2*i + 3*(nrow(concat) + 2),] <- paste(chunks[16], chunks[54], chunks[45], chunks[31], chunks[7], chunks[64], chunks[6], sep = "")
      alignments[2*i + 4*(nrow(concat) + 2),] <- paste(chunks[15], chunks[24], chunks[8], chunks[11], chunks[53], chunks[52], chunks[51], chunks[20], chunks[26], sep = "")
      alignments[2*i + 5*(nrow(concat) + 2),] <- paste(chunks[14], chunks[17], chunks[9], chunks[27], chunks[22], chunks[28], sep = "")
      alignments[2*i + 6*(nrow(concat) + 2),] <- paste(chunks[10], chunks[21], chunks[13], sep = "")
      alignments[2*i + 7*(nrow(concat) + 2),] <- paste(chunks[62], chunks[37], chunks[59], chunks[29], chunks[12], chunks[58], chunks[46], chunks[66], chunks[44], chunks[18], sep = "")
      alignments[2*i + 8*(nrow(concat) + 2),] <- paste(chunks[40], chunks[39], chunks[49], chunks[19], chunks[32], chunks[38], sep = "")
      alignments[2*i + 9*(nrow(concat) + 2),] <- paste(chunks[35], chunks[60], chunks[33], chunks[43], chunks[30], sep = "")
      alignments[2*i + 10*(nrow(concat) + 2),] <- paste(chunks[36], chunks[48], chunks[65], sep = "")
      alignments[2*i + 11*(nrow(concat) + 2),] <- paste(chunks[56], chunks[50], chunks[41], sep = "")
    }
    write.table(alignments, "/Users/David/Downloads/pamlconcatpartitioned.phy", quote = FALSE, row.names = FALSE, col.names = FALSE, na = "")
    ```

2. Manually add the information about the number of taxa and sites in each partition.

To obtain a single estimate that could be used for the gamma-Dirichlet hyperprior on rates (`rgene_gamma`), a weighted average of these values was computed, with each rate weighted by the length of the corresponding partition:

```{r, echo = FALSE}
(100*0.126608 + 200*0.087695 + 300*0.033200 + 350*0.072678 + 450*0.072362 + 300*0.158487 + 150*0.188372 + 497*0.107932 + 300*0.060550 + 250*0.111402 + 150*0.026772 + 150*0.184536)/3197
```

The shape parameter of the gamma-Dirichlet distribution ($\alpha$) was set to 2 and the rate parameter ($\beta$) was chosen so that the mean (calculated as $\frac{\alpha}{\beta}$) was equal to the rate above (expressed as the number of substitutions per 10 million years):

```{r, echo = FALSE}
20 / 0.09550072
```

The hyperprior on the mean of the rate distribution is distributed as follows:

```{r, echo=FALSE}
curve(dgamma(x, 2, 209.42), from=0, to=0.1, 
      main = "Prior on the mean of the rate distribution", xlab = "Mean value", ylab = "Probability density")
```

The mean of the gamma hyperprior on the variance of the log rate was set to 0.1 by setting $\alpha$ equal to 1 and $\beta$ equal to 10. This corresponds closely to the mean of the `ucld.stdev` hyperprior in BEAST (0.3 -- note that while BEAST places the prior on the standard deviation of the rate distribution, MCMCTree assigns the prior to the variance, or the square of the standard deviation).

The lognormal distribution of rates is plotted below, with the mean and variance (in log-space) set equal to the means of the respective hyperpriors:

```{r, echo = FALSE}
curve(dlnorm(x, meanlog = log(2/209.42), sdlog = sqrt(1/10)), from=0, to=0.1, 
      main = "Relaxed clock rate distribution", xlab = "Substitutions per site per 10 million years", ylab = "Probability density")
```

Finally, since there are multiple loci, the Dirichlet concentration parameter $\alpha_D$ was specified and set to the default value of 1, which is described as producing "a reasonable partitioning" in the MCMCTree manual.

The full configuration file is shown below:

```{r comment='', echo = FALSE}
cat(readLines("/Users/David/Grive/Alfaro_Lab/PAML_mcmcTREE/Chunks/chunkmcmctree.ctl"), sep = '\n')
```

The initial analyses (run under the `usedata = 3` option to calculate the Hessian matrices for the branch lengths) produced the following warning messages:

```
xmax = 0.0000e+00 close to zero at 226!
xmax = 0.0000e+00 close to zero at 225!
xmax = 0.0000e+00 close to zero at 223!
xmax = 0.0000e+00 close to zero at 224!
```

However, these did not cause baseml to crash, and the Hessian matrices were successfully written into `out.BV` files. Therefore, the `usedata` variable was set to 2, the `out.BV` files were moved to `in.BV`, and four separate MCMC chains with a length of 75 million generations (as specified in the configuration file above) were started.

# Refs:

Ronquist F, Deans AR 2010 Bayesian phylogenetics and its influence on insect systematics. Annu Rev Entomol 55: 189--206

Warnock RCM, Parham JF, Joyce WG, Lyson TR, Donoghue PCJ 2014 Calibration uncertainty in molecular dating analyses: there is no substitute for the prior evaluation of time priors. Proc R Soc B 282(1798): 20141013